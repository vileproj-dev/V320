# ARQV30 Enhanced v3.0 - External AI Verifier Configuration
# Default configuration for the independent AI verification module

# Confidence Thresholds
thresholds:
  approval: 0.75
  rejection: 0.35
  high_confidence: 0.85
  low_confidence: 0.5
  sentiment_neutral: 0.1
  bias_high_risk: 0.7
  llm_minimum: 0.6

# Sentiment Analysis Configuration  
sentiment_analysis:
  enabled: true
  use_vader: true
  use_textblob: true
  polarity_weights:
    positive: 1.1
    negative: 0.8
    neutral: 1.0
  
# Bias & Disinformation Detection
bias_detection:
  enabled: true
  bias_keywords:
    - "sempre"
    - "nunca" 
    - "todos sabem"
    - "é óbvio"
    - "sem dúvida"
    - "claramente"
  disinformation_patterns:
    - "estudos comprovam"
    - "especialistas dizem"
    - "pesquisas mostram"
    - "é cientificamente provado"
  rhetoric_devices:
    - "apelo ao medo"
    - "falácia ad hominem"
    - "generalização"
    - "cherry picking"

# LLM Reasoning Service
llm_reasoning:
  enabled: true
  provider: "gemini"  # "gemini", "openai", "groq"
  model: "gemini-pro"
  max_tokens: 1000
  temperature: 0.3
  confidence_threshold: 0.6
  use_for_ambiguous_cases: true
  ambiguous_range:
    min: 0.4
    max: 0.75

# Rule Engine Configuration
rules:
  - name: "low_confidence_rejection"
    condition: "overall_confidence < 0.35"
    action:
      status: "rejected"
      reason: "Confidence muito baixa"
      confidence_adjustment: -0.2
      
  - name: "high_risk_bias_rejection"
    condition: "overall_risk >= 0.7"
    action:
      status: "rejected"
      reason: "Alto risco de viés/desinformação detectado"
      confidence_adjustment: -0.3
      
  - name: "high_confidence_approval"
    condition: "overall_confidence >= 0.85"
    action:
      status: "approved"
      reason: "Alta confiança"
      confidence_adjustment: 0.0

# Contextual Analysis
contextual_analysis:
  enabled: true
  check_consistency: true
  analyze_source_reliability: true
  verify_temporal_coherence: true

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "ai_verifier.log"

# Performance Settings
performance:
  batch_size: 10
  max_processing_time: 300  # seconds
  parallel_processing: true
  cache_enabled: true