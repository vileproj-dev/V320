
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v3.0 - Visual Content Capture
Captura de screenshots e conte√∫do visual usando Selenium
"""

import os
import logging
import time
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path

# Selenium imports
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager

logger = logging.getLogger(__name__)

class VisualContentCapture:
    """Capturador de conte√∫do visual usando Selenium"""

    def __init__(self):
        """Inicializa o capturador visual"""
        self.driver = None
        self.wait_timeout = 10
        self.page_load_timeout = 30
        
        logger.info("üì∏ Visual Content Capture inicializado")
        
        # API keys para busca no Google Images
        self.serper_api_keys = self._load_serper_keys()
        self.current_serper_index = 0

    def _load_serper_keys(self) -> list:
        """Carrega chaves da API Serper para busca de imagens"""
        keys = []
        
        # Chave principal
        main_key = os.getenv('SERPER_API_KEY')
        if main_key:
            keys.append(main_key)
        
        # Chaves numeradas
        counter = 1
        while True:
            numbered_key = os.getenv(f'SERPER_API_KEY_{counter}')
            if numbered_key:
                keys.append(numbered_key)
                counter += 1
            else:
                break
        
        logger.info(f"‚úÖ {len(keys)} chaves Serper carregadas para busca de imagens")
        return keys

    def _get_next_serper_key(self) -> Optional[str]:
        """Obt√©m pr√≥xima chave Serper com rota√ß√£o"""
        if not self.serper_api_keys:
            return None
            
        key = self.serper_api_keys[self.current_serper_index]
        self.current_serper_index = (self.current_serper_index + 1) % len(self.serper_api_keys)
        return key

    def _try_google_images_extraction(self, post_url: str, filename: str, session_dir: Path) -> Dict[str, Any]:
        """
        PROCEDIMENTO PRIORIT√ÅRIO: Busca imagem no Google Images
        Implementa exatamente o procedimento descrito no anexo com melhorias
        """
        try:
            logger.info(f"üîç PRIORIDADE 1: Buscando imagem no Google Images para {post_url}")
            
            # Prepara m√∫ltiplas queries para aumentar chance de sucesso
            queries = [
                post_url,  # URL completa
                post_url.replace('https://', '').replace('http://', ''),  # Sem protocolo
                f'"{post_url}"',  # Com aspas
                f'site:instagram.com {post_url.split("/")[-2] if "/" in post_url else post_url}'  # Estrat√©gia alternativa
            ]
            
            for i, query in enumerate(queries, 1):
                logger.info(f"üîç Tentativa {i}/{len(queries)} com query: {query}")
                
                # Usa API Serper para buscar imagens
                api_key = self._get_next_serper_key()
                if not api_key:
                    logger.warning("‚ö†Ô∏è Nenhuma chave Serper dispon√≠vel")
                    continue
                
                import requests
                
                url = "https://google.serper.dev/images"
                payload = {
                    "q": query,
                    "num": 10,  # Busca 10 imagens para ter mais alternativas
                    "safe": "off",
                    "gl": "br",
                    "hl": "pt-br",
                    "imgSize": "large",
                    "imgType": "photo"
                }
                headers = {'X-API-KEY': api_key, 'Content-Type': 'application/json'}
                
                try:
                    response = requests.post(url, json=payload, headers=headers, timeout=30)
                    
                    if response.status_code == 200:
                        data = response.json()
                        images = data.get('images', [])
                        
                        logger.info(f"üìä Google Images retornou {len(images)} imagens para query {i}")
                        
                        # Tenta baixar cada imagem at√© conseguir uma
                        for j, image in enumerate(images, 1):
                            image_url = image.get('imageUrl')
                            if not image_url:
                                continue
                                
                            logger.info(f"‚¨áÔ∏è Tentando baixar imagem {j}: {image_url[:100]}...")
                            
                            success = self._download_image_from_url(image_url, f"{filename}_{i}_{j}", session_dir)
                            if success:
                                # Procura o arquivo baixado
                                for ext in ['.jpg', '.png', '.webp', '.jpeg']:
                                    screenshot_path = session_dir / f"{filename}_{i}_{j}{ext}"
                                    if screenshot_path.exists():
                                        logger.info(f"‚úÖ SUCESSO: Imagem baixada via Google Images: {screenshot_path}")
                                        
                                        # Renomeia para nome padr√£o
                                        final_path = session_dir / f"{filename}{ext}"
                                        screenshot_path.rename(final_path)
                                        
                                        return {
                                            'success': True,
                                            'url': post_url,
                                            'image_source': image_url,
                                            'title': f"Imagem extra√≠da do Google Images (Query {i})",
                                            'description': f"Imagem encontrada via busca no Google Images",
                                            'filename': final_path.name,
                                            'filepath': str(final_path),
                                            'filesize': final_path.stat().st_size,
                                            'method': 'google_images_search',
                                            'query_used': query,
                                            'image_position': j,
                                            'timestamp': datetime.now().isoformat()
                                        }
                            
                            # Rate limiting entre tentativas
                            time.sleep(0.3)
                    
                    elif response.status_code == 429:
                        logger.warning("‚ö†Ô∏è Rate limit Serper - aguardando 2s...")
                        time.sleep(2)
                        continue
                    else:
                        logger.warning(f"‚ö†Ô∏è Status {response.status_code} para query {i}")
                
                except requests.RequestException as e:
                    logger.warning(f"‚ö†Ô∏è Erro de rede na query {i}: {e}")
                    continue
                
                # Pausa entre queries
                time.sleep(1)
            
            logger.warning("‚ö†Ô∏è Todas as tentativas do Google Images falharam")
            
        except Exception as e:
            logger.error(f"‚ùå Erro cr√≠tico no Google Images: {str(e)}")
        
        return {'success': False, 'error': 'Google Images search failed after all attempts'}

    def _download_image_from_url(self, image_url: str, filename: str, session_dir: Path) -> bool:
        """Baixa imagem da URL com valida√ß√£o robusta e m√∫ltiplas tentativas"""
        max_attempts = 3
        
        for attempt in range(max_attempts):
            try:
                logger.info(f"‚¨áÔ∏è Tentativa {attempt + 1}/{max_attempts} de download: {image_url[:100]}...")
                
                import requests
                
                # Headers mais robustos para evitar bloqueios
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                    'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Cache-Control': 'no-cache',
                    'Pragma': 'no-cache',
                    'Sec-Fetch-Dest': 'image',
                    'Sec-Fetch-Mode': 'no-cors',
                    'Sec-Fetch-Site': 'cross-site'
                }
                
                # Timeout progressivo
                timeout = 15 + (attempt * 10)  # 15, 25, 35 segundos
                
                response = requests.get(
                    image_url, 
                    headers=headers, 
                    timeout=timeout, 
                    stream=True,
                    allow_redirects=True,
                    verify=True
                )
                
                response.raise_for_status()
                
                # Verifica Content-Type
                content_type = response.headers.get('content-type', '').lower()
                logger.info(f"üìÑ Content-Type: {content_type}")
                
                # Determina extens√£o baseada no Content-Type e URL
                extension = '.jpg'  # Default
                if 'jpeg' in content_type or 'jpg' in content_type:
                    extension = '.jpg'
                elif 'png' in content_type:
                    extension = '.png'
                elif 'webp' in content_type:
                    extension = '.webp'
                elif 'gif' in content_type:
                    extension = '.gif'
                elif image_url.lower().endswith('.png'):
                    extension = '.png'
                elif image_url.lower().endswith('.webp'):
                    extension = '.webp'
                elif image_url.lower().endswith('.gif'):
                    extension = '.gif'
                
                image_path = session_dir / f"{filename}{extension}"
                
                # Download com valida√ß√£o de tamanho
                total_size = 0
                with open(image_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:  # Filter out keep-alive chunks
                            f.write(chunk)
                            total_size += len(chunk)
                            
                            # Limite de 50MB para evitar downloads gigantes
                            if total_size > 50 * 1024 * 1024:
                                logger.warning("‚ö†Ô∏è Arquivo muito grande (>50MB), abortando")
                                raise Exception("Arquivo muito grande")
                
                # Valida√ß√£o final
                if image_path.exists():
                    file_size = image_path.stat().st_size
                    logger.info(f"üìä Arquivo baixado: {file_size:,} bytes")
                    
                    # Verifica tamanho m√≠nimo (3KB) e m√°ximo (50MB)
                    if 3000 <= file_size <= 50 * 1024 * 1024:
                        # Valida√ß√£o adicional: tenta ler o in√≠cio do arquivo para verificar se √© uma imagem
                        try:
                            with open(image_path, 'rb') as f:
                                header = f.read(50)
                                
                            # Assinaturas de arquivos de imagem
                            image_signatures = [
                                b'\xff\xd8\xff',  # JPEG
                                b'\x89PNG\r\n\x1a\n',  # PNG
                                b'GIF8',  # GIF
                                b'RIFF',  # WebP (starts with RIFF)
                                b'<svg',  # SVG
                            ]
                            
                            is_valid_image = any(header.startswith(sig) for sig in image_signatures)
                            
                            if is_valid_image:
                                logger.info(f"‚úÖ DOWNLOAD SUCESSO: {image_path} ({file_size:,} bytes)")
                                return True
                            else:
                                logger.warning(f"‚ö†Ô∏è Arquivo n√£o parece ser uma imagem v√°lida")
                                image_path.unlink()  # Remove arquivo inv√°lido
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Erro na valida√ß√£o da imagem: {e}")
                            
                    else:
                        logger.warning(f"‚ö†Ô∏è Tamanho inv√°lido: {file_size} bytes (m√≠n: 3KB, m√°x: 50MB)")
                        if image_path.exists():
                            image_path.unlink()
                
            except requests.exceptions.Timeout:
                logger.warning(f"‚è∞ Timeout na tentativa {attempt + 1}")
            except requests.exceptions.ConnectionError:
                logger.warning(f"üåê Erro de conex√£o na tentativa {attempt + 1}")
            except requests.exceptions.HTTPError as e:
                logger.warning(f"üì° Erro HTTP {e.response.status_code} na tentativa {attempt + 1}")
                # Se for 404, 403, ou similar, n√£o vale a pena tentar novamente
                if e.response.status_code in [404, 403, 401, 410]:
                    break
            except Exception as e:
                logger.warning(f"‚ùå Erro na tentativa {attempt + 1}: {str(e)}")
            
            # Pausa entre tentativas (backoff exponencial)
            if attempt < max_attempts - 1:
                sleep_time = 2 ** attempt  # 1s, 2s, 4s
                logger.info(f"‚è≥ Aguardando {sleep_time}s antes da pr√≥xima tentativa...")
                time.sleep(sleep_time)
        
        logger.error(f"‚ùå FALHA TOTAL: N√£o foi poss√≠vel baixar a imagem ap√≥s {max_attempts} tentativas")
        return False

    def _setup_driver(self) -> webdriver.Chrome:
        """Configura o driver do Chrome em modo headless"""
        try:
            chrome_options = Options()
            
            # Configura√ß√µes para modo headless e otimiza√ß√£o no Replit
            chrome_options.add_argument("--headless")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--disable-web-security")
            chrome_options.add_argument("--disable-features=VizDisplayCompositor")
            chrome_options.add_argument("--remote-debugging-port=9222")
            chrome_options.add_argument("--window-size=1920,1080")
            chrome_options.add_argument("--disable-extensions")
            chrome_options.add_argument("--disable-plugins")
            chrome_options.add_argument("--disable-images")  # Para economizar banda
            chrome_options.add_argument("--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36")
            
            # Usa selenium_checker para configura√ß√£o robusta
            from .selenium_checker import selenium_checker
            
            # Executa verifica√ß√£o completa
            check_results = selenium_checker.full_check()
            
            if not check_results['selenium_ready']:
                raise Exception("Selenium n√£o est√° configurado corretamente")
            
            # Configura o Chrome com o melhor caminho encontrado
            best_chrome_path = check_results['best_chrome_path']
            if best_chrome_path:
                chrome_options.binary_location = best_chrome_path
                logger.info(f"‚úÖ Chrome configurado: {best_chrome_path}")
            
            # Tenta usar ChromeDriverManager primeiro
            try:
                service = Service(ChromeDriverManager().install())
                driver = webdriver.Chrome(service=service, options=chrome_options)
                logger.info("‚úÖ ChromeDriverManager funcionou")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è ChromeDriverManager falhou: {e}, usando chromedriver do sistema")
                # Fallback para chromedriver do sistema
                driver = webdriver.Chrome(options=chrome_options)
            
            driver.set_page_load_timeout(self.page_load_timeout)
            
            logger.info("‚úÖ Chrome driver configurado com sucesso")
            return driver
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao configurar Chrome driver: {e}")
            raise

    def _create_session_directory(self, session_id: str) -> Path:
        """Cria diret√≥rio para a sess√£o"""
        try:
            session_dir = Path("analyses_data") / "files" / session_id
            session_dir.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"üìÅ Diret√≥rio criado: {session_dir}")
            return session_dir
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao criar diret√≥rio: {e}")
            raise

    def _take_screenshot(self, url: str, filename: str, session_dir: Path) -> Dict[str, Any]:
        """Captura screenshot com PRIORIDADE para Google Images e detec√ß√£o de p√°ginas de login"""
        
        # PRIORIDADE 1: SEMPRE tenta Google Images primeiro (para qualquer URL)
        logger.info(f"üéØ ESTRAT√âGIA PRIORIT√ÅRIA: Google Images para {url}")
        google_image_result = self._try_google_images_extraction(url, filename, session_dir)
        if google_image_result and google_image_result.get('success'):
            logger.info(f"‚úÖ SUCESSO VIA GOOGLE IMAGES: {url}")
            return google_image_result
        
        # PRIORIDADE 2: Screenshot tradicional apenas se Google Images falhar
        logger.info(f"üîÑ FALLBACK: Screenshot tradicional para {url}")
        
        try:
            logger.info(f"üì∏ Capturando screenshot: {url}")
            
            # Acessa a URL
            self.driver.get(url)
            
            # Aguarda o carregamento da p√°gina
            try:
                WebDriverWait(self.driver, self.wait_timeout).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
            except TimeoutException:
                logger.warning(f"‚ö†Ô∏è Timeout aguardando carregamento de {url}")
            
            # Aguarda um pouco mais para renderiza√ß√£o completa
            time.sleep(2)
            
            # NOVA FUNCIONALIDADE: Detectar p√°ginas de login/bloqueio
            if self._is_login_or_blocked_page():
                logger.warning(f"üö´ P√ÅGINA DE LOGIN/BLOQUEIO DETECTADA: {url}")
                # Tenta estrat√©gias alternativas
                alternative_result = self._try_alternative_content_extraction(url, filename, session_dir)
                if alternative_result and alternative_result.get('success'):
                    return alternative_result
                
                # Se n√£o conseguir alternativa, retorna erro espec√≠fico
                return {
                    'success': False,
                    'error': 'login_page_detected',
                    'url': url,
                    'message': 'P√°gina de login ou bloqueio detectada - screenshot n√£o capturado',
                    'timestamp': datetime.now().isoformat()
                }
            
            # Captura informa√ß√µes da p√°gina
            page_title = self.driver.title or "Sem t√≠tulo"
            page_url = self.driver.current_url
            
            # Tenta obter meta description
            meta_description = ""
            try:
                meta_element = self.driver.find_element(By.CSS_SELECTOR, 'meta[name="description"]')
                meta_description = meta_element.get_attribute("content") or ""
            except:
                pass
            
            # Define o caminho do arquivo
            screenshot_path = session_dir / f"{filename}.png"
            
            # Captura o screenshot
            self.driver.save_screenshot(str(screenshot_path))
            
            # Verifica se o arquivo foi criado
            if screenshot_path.exists() and screenshot_path.stat().st_size > 0:
                logger.info(f"‚úÖ Screenshot salvo: {screenshot_path}")
                
                return {
                    'success': True,
                    'url': url,
                    'final_url': page_url,
                    'title': page_title,
                    'description': meta_description,
                    'filename': f"{filename}.png",
                    'filepath': str(screenshot_path),
                    'filesize': screenshot_path.stat().st_size,
                    'timestamp': datetime.now().isoformat()
                }
            else:
                raise Exception("Screenshot n√£o foi criado ou est√° vazio")
                
        except Exception as e:
            error_msg = f"Erro ao capturar screenshot de {url}: {e}"
            logger.error(f"‚ùå {error_msg}")
            
            return {
                'success': False,
                'url': url,
                'error': error_msg,
                'timestamp': datetime.now().isoformat()
            }

    async def capture_screenshots(self, urls: List[str], session_id: str) -> Dict[str, Any]:
        """
        Captura screenshots de uma lista de URLs
        
        Args:
            urls: Lista de URLs para capturar
            session_id: ID da sess√£o para organiza√ß√£o
        """
        logger.info(f"üì∏ Iniciando captura de {len(urls)} screenshots para sess√£o {session_id}")
        
        # Resultado da opera√ß√£o
        capture_results = {
            'session_id': session_id,
            'total_urls': len(urls),
            'successful_captures': 0,
            'failed_captures': 0,
            'screenshots': [],
            'errors': [],
            'start_time': datetime.now().isoformat(),
            'session_directory': None
        }
        
        try:
            # Cria diret√≥rio da sess√£o
            session_dir = self._create_session_directory(session_id)
            capture_results['session_directory'] = str(session_dir)
            
            # Configura o driver
            self.driver = self._setup_driver()
            
            # Processa cada URL
            for i, url in enumerate(urls, 1):
                if not url or not url.startswith(('http://', 'https://')):
                    logger.warning(f"‚ö†Ô∏è URL inv√°lida ignorada: {url}")
                    capture_results['failed_captures'] += 1
                    capture_results['errors'].append(f"URL inv√°lida: {url}")
                    continue
                
                try:
                    # Gera nome do arquivo
                    filename = f"screenshot_{i:03d}"
                    
                    # Captura o screenshot
                    result = self._take_screenshot(url, filename, session_dir)
                    
                    if result['success']:
                        capture_results['successful_captures'] += 1
                        capture_results['screenshots'].append(result)
                    else:
                        capture_results['failed_captures'] += 1
                        capture_results['errors'].append(result['error'])
                    
                    # Pequena pausa entre capturas para n√£o sobrecarregar
                    await asyncio.sleep(1)
                    
                except Exception as e:
                    error_msg = f"Erro processando URL {url}: {e}"
                    logger.error(f"‚ùå {error_msg}")
                    capture_results['failed_captures'] += 1
                    capture_results['errors'].append(error_msg)
            
            # Finaliza a captura
            capture_results['end_time'] = datetime.now().isoformat()
            
            logger.info(f"‚úÖ Captura conclu√≠da: {capture_results['successful_captures']}/{capture_results['total_urls']} sucessos")
            
        except Exception as e:
            error_msg = f"Erro cr√≠tico na captura: {e}"
            logger.error(f"‚ùå {error_msg}")
            capture_results['critical_error'] = error_msg
            
        finally:
            # Fecha o driver se estiver aberto
            if self.driver:
                try:
                    self.driver.quit()
                    logger.info("‚úÖ Chrome driver fechado")
                except Exception as e:
                    logger.error(f"‚ùå Erro ao fechar driver: {e}")
                self.driver = None
        
        return capture_results

    def select_top_urls(self, all_results: Dict[str, Any], max_urls: int = 10) -> List[str]:
        """
        Seleciona as URLs mais relevantes dos resultados de busca
        
        Args:
            all_results: Resultados consolidados de todas as buscas
            max_urls: N√∫mero m√°ximo de URLs para retornar
        """
        logger.info(f"üéØ Selecionando top {max_urls} URLs mais relevantes")
        
        # Handle both dict and list formats
        if isinstance(all_results, dict):
            all_urls = all_results.get('consolidated_urls', [])
        elif isinstance(all_results, list):
            all_urls = all_results
        else:
            logger.warning(f"‚ö†Ô∏è Formato inesperado de all_results: {type(all_results)}")
            all_urls = []
        
        if not all_urls:
            logger.warning("‚ö†Ô∏è Nenhuma URL encontrada nos resultados")
            return []
        
        # Por enquanto, retorna as primeiras URLs √∫nicas
        # Em uma implementa√ß√£o mais sofisticada, poderia ranquear por relev√¢ncia
        unique_urls = []
        seen_domains = set()
        
        for url in all_urls:
            try:
                # Extrai dom√≠nio para diversificar
                from urllib.parse import urlparse
                domain = urlparse(url).netloc.lower()
                
                # Adiciona URL se for de dom√≠nio novo ou se ainda n√£o temos URLs suficientes
                if domain not in seen_domains or len(unique_urls) < max_urls // 2:
                    unique_urls.append(url)
                    seen_domains.add(domain)
                    
                    if len(unique_urls) >= max_urls:
                        break
                        
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro processando URL {url}: {e}")
                continue
        
        logger.info(f"‚úÖ Selecionadas {len(unique_urls)} URLs de {len(seen_domains)} dom√≠nios diferentes")
        return unique_urls

    def cleanup_old_screenshots(self, days_old: int = 7):
        """Remove screenshots antigos para economizar espa√ßo"""
        try:
            files_dir = Path("analyses_data") / "files"
            if not files_dir.exists():
                return
            
            cutoff_time = time.time() - (days_old * 24 * 60 * 60)
            removed_count = 0
            
            for session_dir in files_dir.iterdir():
                if session_dir.is_dir():
                    for screenshot in session_dir.glob("*.png"):
                        if screenshot.stat().st_mtime < cutoff_time:
                            screenshot.unlink()
                            removed_count += 1
                    
                    # Remove diret√≥rio se estiver vazio
                    try:
                        session_dir.rmdir()
                    except OSError:
                        pass  # Diret√≥rio n√£o est√° vazio
            
            if removed_count > 0:
                logger.info(f"üßπ Removidos {removed_count} screenshots antigos")
                
        except Exception as e:
            logger.error(f"‚ùå Erro na limpeza: {e}")

    def _is_login_or_blocked_page(self) -> bool:
        """Detecta se a p√°gina atual √© uma p√°gina de login ou bloqueio"""
        try:
            # Verifica o t√≠tulo da p√°gina
            page_title = self.driver.title.lower() if self.driver.title else ""
            
            # Palavras-chave que indicam p√°ginas de login/bloqueio
            login_keywords = [
                'login', 'sign in', 'log in', 'entrar', 'acesso', 'authentication',
                'blocked', 'bloqueado', 'access denied', 'acesso negado',
                'captcha', 'robot', 'verification', 'verifica√ß√£o',
                'forbidden', 'proibido', '403', '401', 'unauthorized',
                'please sign in', 'fa√ßa login', 'entre na sua conta'
            ]
            
            # Verifica t√≠tulo
            for keyword in login_keywords:
                if keyword in page_title:
                    logger.info(f"üö´ Palavra-chave de login detectada no t√≠tulo: '{keyword}'")
                    return True
            
            # Verifica URL atual
            current_url = self.driver.current_url.lower()
            url_login_keywords = [
                '/login', '/signin', '/auth', '/accounts/login',
                '/user/login', '/entrar', '/acesso'
            ]
            
            for keyword in url_login_keywords:
                if keyword in current_url:
                    logger.info(f"üö´ Palavra-chave de login detectada na URL: '{keyword}'")
                    return True
            
            # Verifica elementos na p√°gina
            try:
                # Procura por campos de login t√≠picos
                login_elements = [
                    'input[type="password"]',
                    'input[name*="password"]',
                    'input[name*="login"]',
                    'input[name*="email"]',
                    'input[name*="username"]',
                    'button[type="submit"]',
                    '.login-form',
                    '.signin-form',
                    '#login',
                    '#signin'
                ]
                
                login_element_count = 0
                for selector in login_elements:
                    try:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        if elements:
                            login_element_count += len(elements)
                    except:
                        continue
                
                # Se encontrar muitos elementos de login, provavelmente √© uma p√°gina de login
                if login_element_count >= 2:
                    logger.info(f"üö´ {login_element_count} elementos de login detectados na p√°gina")
                    return True
                
                # Verifica texto espec√≠fico na p√°gina
                try:
                    body_text = self.driver.find_element(By.TAG_NAME, "body").text.lower()
                    login_text_keywords = [
                        'please sign in', 'fa√ßa login', 'entre na sua conta',
                        'access denied', 'acesso negado', 'login required',
                        'you need to sign in', 'voc√™ precisa fazer login'
                    ]
                    
                    for keyword in login_text_keywords:
                        if keyword in body_text:
                            logger.info(f"üö´ Texto de login detectado: '{keyword}'")
                            return True
                            
                except:
                    pass
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao verificar elementos de login: {e}")
            
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Erro na detec√ß√£o de p√°gina de login: {e}")
            return False

    def _try_alternative_content_extraction(self, url: str, filename: str, session_dir: Path) -> Dict[str, Any]:
        """Tenta estrat√©gias alternativas quando detecta p√°gina de login"""
        logger.info(f"üîÑ Tentando extra√ß√£o alternativa para: {url}")
        
        # Estrat√©gia 1: Busca no Google Images com dom√≠nio espec√≠fico
        try:
            from urllib.parse import urlparse
            domain = urlparse(url).netloc
            
            # Cria query espec√≠fica para o dom√≠nio
            domain_query = f"site:{domain} screenshot content"
            
            logger.info(f"üéØ Tentando Google Images com query espec√≠fica: {domain_query}")
            google_result = self._try_google_images_with_query(domain_query, filename, session_dir)
            
            if google_result and google_result.get('success'):
                logger.info(f"‚úÖ SUCESSO com Google Images alternativo")
                return google_result
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro na estrat√©gia alternativa 1: {e}")
        
        # Estrat√©gia 2: Tenta acessar com User-Agent diferente
        try:
            logger.info(f"üîÑ Tentando com User-Agent alternativo")
            
            # Salva configura√ß√£o atual
            original_user_agent = self.driver.execute_script("return navigator.userAgent;")
            
            # Tenta com User-Agent de bot/crawler
            self.driver.execute_cdp_cmd('Network.setUserAgentOverride', {
                "userAgent": "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)"
            })
            
            # Tenta acessar novamente
            self.driver.get(url)
            time.sleep(3)
            
            # Verifica se ainda √© p√°gina de login
            if not self._is_login_or_blocked_page():
                logger.info(f"‚úÖ User-Agent alternativo funcionou!")
                
                # Captura screenshot
                screenshot_path = session_dir / f"{filename}_alt.png"
                self.driver.save_screenshot(str(screenshot_path))
                
                if screenshot_path.exists() and screenshot_path.stat().st_size > 0:
                    return {
                        'success': True,
                        'url': url,
                        'title': self.driver.title or "Conte√∫do alternativo",
                        'description': "Capturado com User-Agent alternativo",
                        'filename': f"{filename}_alt.png",
                        'filepath': str(screenshot_path),
                        'filesize': screenshot_path.stat().st_size,
                        'method': 'alternative_user_agent',
                        'timestamp': datetime.now().isoformat()
                    }
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro na estrat√©gia alternativa 2: {e}")
        
        # Se todas as estrat√©gias falharam
        logger.warning(f"‚ö†Ô∏è Todas as estrat√©gias alternativas falharam para: {url}")
        return {'success': False, 'error': 'all_alternative_strategies_failed'}

    def _try_google_images_with_query(self, query: str, filename: str, session_dir: Path) -> Dict[str, Any]:
        """Busca imagens no Google com query espec√≠fica"""
        try:
            if not self.serper_api_keys:
                return {'success': False, 'error': 'no_serper_keys'}
            
            import requests
            
            api_key = self.serper_api_keys[self.current_serper_index % len(self.serper_api_keys)]
            
            url = "https://google.serper.dev/images"
            payload = {
                "q": query,
                "num": 5,
                "safe": "off",
                "gl": "br",
                "hl": "pt-br",
                "imgSize": "large"
            }
            headers = {'X-API-KEY': api_key, 'Content-Type': 'application/json'}
            
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                images = data.get('images', [])
                
                for i, image in enumerate(images, 1):
                    image_url = image.get('imageUrl')
                    if not image_url:
                        continue
                    
                    success = self._download_image_from_url(image_url, f"{filename}_alt_{i}", session_dir)
                    if success:
                        for ext in ['.jpg', '.png', '.webp', '.jpeg']:
                            screenshot_path = session_dir / f"{filename}_alt_{i}{ext}"
                            if screenshot_path.exists():
                                final_path = session_dir / f"{filename}_alt{ext}"
                                screenshot_path.rename(final_path)
                                
                                return {
                                    'success': True,
                                    'image_source': image_url,
                                    'title': f"Imagem alternativa via Google Images",
                                    'description': f"Query: {query}",
                                    'filename': final_path.name,
                                    'filepath': str(final_path),
                                    'filesize': final_path.stat().st_size,
                                    'method': 'google_images_alternative',
                                    'timestamp': datetime.now().isoformat()
                                }
            
            return {'success': False, 'error': 'google_images_alternative_failed'}
            
        except Exception as e:
            logger.error(f"‚ùå Erro na busca alternativa do Google Images: {e}")
            return {'success': False, 'error': str(e)}

# Inst√¢ncia global
visual_content_capture = VisualContentCapture()
